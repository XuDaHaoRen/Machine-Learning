{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 SVM 支撑向量机（Support Vector Machine）概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM 尝试找到一个最优的决策边界，距离两个类别的最近的样本最远。而这些决定决策边界的线的向量称为支撑向量。<br/>\n",
    "SVM 就可以转换成这样的一个问题：求得决策边界两边的支撑向量距离决策边界最远，即求点到线的距离最远"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.Hard Margin SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 点到线的距离公式：\n",
    "可以解决一个线性分割问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要解决的是找到一条可以分割两个分类的线，使得支持向量到达直线的距离最远：\n",
    "$$\\frac{|Ax+By+C|}{\\sqrt{A^{2}+B^{2}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "扩展到 n 维空间可以理解为：\n",
    "$$\\frac{|w^{T}x+b|}{||w||}$$\n",
    "其中决策边界为：\n",
    "$$w^{T}x+b =0$$\n",
    "需要注意的是这个式子就是这样的，并不是说我们将样本 x 带入表达式使得等式为 0<br/>\n",
    "其中 ||w|| 代表对 w 取模：\n",
    "$$\\sqrt{w_{1}^{2}+w_{2}^{2}+...+w_{3}^{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们设其中一个类别的 y = 1，则它的算法公式可以写为（这里可以直接将绝对值符号去掉）：$$\\frac{w^{T}x^{(i)}+b}{||w||}\\geq d ->  \\frac{w^{T}x^{(i)}+b}{||w||d}\\geq 1-> w_{d}^{T}x^{(i)}+{b_{d}} \\geq 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>如果我们设其中一个类别的 y = -1 ，则它的算法公式可以写为（这里去绝对值符号的时候需要变号）：<br/>\n",
    "$$\\frac{w^{T}x^{(i)}+b}{||w||}\\leq -d->\\frac{w^{T}x^{(i)}+b}{||w||d}\\leq -1-> w_{d}^{T}x^{(i)}+{b_{d}} \\leq -1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据 y 的取值,并且将下标 d 隐藏后，最后这个分段函数可写为：\n",
    "$$y^{(i)}(w^{T}x^{(i)}+b)\\geq 1$$\n",
    "<br/>最后我们使得距离最短，即 $$\\frac{|w^{T}x+b|}{||w||}$$ 最小<br/><br/>\n",
    "又因为满足分段函数，所以最终只需要关注分子最大，即：\n",
    "$$min\\frac{1}{2}||w||^{2}$$ \n",
    "<br/>与平常的求解最大值的方法不一样，（普通函数求导然后就出极值就行），这里是在某种情况下求最优解，所以不能使用简单的求导求极大值的方法，要使用到 欧式算子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.Soft Margin & SVM\n",
    "并不是所有所有的类别都是线性可分的，所以我们可以允许在两条线中间存在一些具有偏差的点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么就可以允许在两条横线之间出现一个偏差大的点，而在 hard margin 中我们所有的点都应该在两条直线之外"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./img/softmargin_concept.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从式子中可以理解为如果 C 越大则 ξ 就要取得越小，那么容错能力就会越弱<br/>\n",
    "在加入 ξ 之后，我们所要求得的公式就变为了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./img/svm_L1L2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
